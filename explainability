jiimport shap

# SHAP requires background data
background_sequence = torch.randn(10, 300, 79)  # Example background data
background_length = torch.randint(1, 300, (10, 1))

# Define SHAP DeepExplainer
explainer = shap.DeepExplainer(model, [background_sequence, background_length])

# Get SHAP values
shap_values = explainer.shap_values([sequence_input, length_vector])

# Visualization for sequence input
shap.summary_plot(shap_values[0], sequence_input.detach().numpy(), plot_type="heatmap")

# Attribution for length vector
print("SHAP Values for Length Vector:", shap_values[1])



import torch
from captum.attr import IntegratedGradients
import matplotlib.pyplot as plt

# Dummy example input
sequence_input = torch.randn(1, 300, 79, requires_grad=True)  # Batch size 1
length_vector = torch.randint(1, 300, (1, 1), requires_grad=True)  # Example length vector

# Assuming your model takes two inputs: sequence_input and length_vector
model.eval()

# Integrated Gradients
ig = IntegratedGradients(model)

# Apply Integrated Gradients
attributions, delta = ig.attribute(inputs=(sequence_input, length_vector), 
                                   target=1,  # Change target as needed
                                   return_convergence_delta=True)

# Visualizing the attribution for the sequence input
plt.figure(figsize=(10, 6))
plt.imshow(attributions[0].squeeze().detach().numpy(), cmap='hot', interpolation='nearest')
plt.colorbar()
plt.title('Integrated Gradients Attribution for Sequence Input')
plt.show()

# For the length vector
print("Attribution for Length Vector:", attributions[1].detach().numpy())




import torch
import torch.nn.functional as F
from captum.attr import IntegratedGradients

# Wrapper model to apply sigmoid on logits
class WrappedModel(torch.nn.Module):
    def __init__(self, model):
        super(WrappedModel, self).__init__()
        self.model = model

    def forward(self, x, lengths):
        logits = self.model(x, lengths)
        return torch.sigmoid(logits)  # Apply sigmoid for attribution

# Use the wrapped model for explainability
wrapped_model = WrappedModel(model)
ig = IntegratedGradients(wrapped_model)

# Compute attributions
attributions, delta = ig.attribute(
    inputs=(sequence_input, length_vector),
    target=0,  # For binary classification, sigmoid outputs a single value
    return_convergence_delta=True
)

# Flatten the attributions for easier processing
attributions_flat = attributions.squeeze(0).detach().numpy().flatten()

# Apply Z-Score normalization
mean_attr = np.mean(attributions_flat)
std_attr = np.std(attributions_flat)

normalized_attributions = (attributions_flat - mean_attr) / std_attr

# Reshape back if needed
normalized_attributions = normalized_attributions.reshape(attributions.shape[1], attributions.shape[2])