Input Data:
Provide the detailed description of the input data used in the model.
The input data includes scanned images of identity documents (e.g., passports, driver’s licenses), machine-readable zones (MRZ), barcodes, and metadata. The data may also include anonymized facial images and document layout features. These are used to extract classification and verification features.

What is the source of the input data used in this model?
The data comes from production transactions captured by Mitek’s identity verification platform. The input documents are collected from real-world scenarios, curated and labeled by trained agents, and anonymized to remove any personally identifiable information (PII).

What steps have been taken to ensure the completeness of the input data?

The system checks for the presence of required zones like barcodes, MRZ, and readable text fields.

Anomalous or partial documents are flagged and excluded.

Data quality checks are conducted nightly using labeled datasets to ensure continuous completeness.

What steps have been taken to ensure the accuracy and integrity of the input data?

Input images are validated for quality, clarity, and completeness.

Labels are generated and verified by human reviewers.

Any ambiguous cases are routed to expert review.

The data is version-controlled and tested against known forgery benchmarks.

If the timeliness of the input data is important for the model’s use case, what steps have been taken to ensure timely data?
Yes, timeliness is critical. The data is collected and labeled on a rolling basis and used in nightly regression tests. For each release, new input samples from the most recent transactions are included to ensure the model adapts to evolving fraud patterns.

Training Data:
Provide the detailed description of the training data used in the model.
The training data consists of over 500,000 anonymized document images across various formats and geographies. These include real and forged documents with labels such as document type, issuing country, MRZ data, and tampering categories (e.g., portrait replacement, barcode edits).

What is the source of the training data used in this model?
The training data is generated from Mitek’s production environment, including identity verification transactions. Data is anonymized and curated from both valid and rejected documents, with additional synthetic forgeries created for training robustness.

What steps have been taken to ensure the completeness of the training data?

Representative samples are taken across all document types and regions.

Forgery samples are deliberately added to train classification on anomalies.

Data is regularly updated to reflect new document formats and forgery techniques.

What steps have been taken to ensure the accuracy and integrity of the training data?

Human reviewers validate and annotate the data using pre-defined rules.

Outlier analysis and quality filters remove low-quality or ambiguous samples.

Historical accuracy metrics guide the inclusion or exclusion of training batches.

If the timeliness of the training data is relevant for the model’s use case, what steps have been taken to ensure timely data?

Training datasets are refreshed with new transaction data in each release cycle (typically 6 weeks).

For performance drops, retraining is initiated with the most recent data.

Response time monitoring and cohort-level evaluations ensure the model remains aligned with current threats.

