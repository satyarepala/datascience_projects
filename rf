
from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import log_loss import numpy as np import pandas as pd

Train a Random Forest model

rf_model = RandomForestClassifier( n_estimators=100,  # Number of trees max_depth=12,  # Maximum depth of trees random_state=42,  # For reproducibility class_weight='balanced'  # Handling class imbalance )

Fit the model

rf_model.fit(X_train, y_train)

Evaluate on test data

y_pred_proba = rf_model.predict_proba(X_test)[:, 1]  # Probability of class 1 loss = log_loss(y_test, y_pred_proba) print(f'Binary Log Loss on test data: {loss:.6f}')

Get feature importance and normalize

feature_importance = rf_model.feature_importances_ normalized_importance = feature_importance / np.sum(feature_importance)

Create a DataFrame for column-wise feature importance

feature_importance_df = pd.DataFrame({"Feature": X_train.columns, "Importance": normalized_importance}) feature_importance_df = feature_importance_df.sort_values(by="Importance", ascending=False) print("Normalized Feature Importance:") print(feature_importance_df)

