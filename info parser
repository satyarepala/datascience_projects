Primary Input to the Model

The model takes the following primary inputs to perform Face Liveness Detection, Face Matching, and Forgery Detection:

1. Live Face Image or Video

Captured through a user’s camera during the application process.

Used for liveness detection (to check if the face is real) and face matching (to compare with the ID document).



2. Identity Document Image

A scanned or photographed copy of an official ID (e.g., passport, driver’s license).

Used for OCR-based text extraction and forgery detection (to identify tampering).



3. Extracted Text Data (via OCR)

Text extracted from the identity document, such as name, date of birth, document number.

Compared against user-provided data for consistency.



4. Metadata from Images/Videos

May include information such as resolution, lighting conditions, and image compression artifacts.

Used for fraud detection (e.g., detecting whether an image has been digitally altered).





---

Review of Inputs with Users or Candidate Group

Direct User Review: The inputs (face image, document image) are usually reviewed by the user during submission. Some systems allow users to retake their image if quality issues are detected.

Automated Quality Checks: The model may automatically flag low



Are Inputs Reviewed with Users or Candidate Output?

The review process depends on the system's design and operational workflow. Below is an explanation of whether the inputs are reviewed with users or a candidate group before generating the final decision.

1. User Review of Inputs (Before Processing)

Users typically review their inputs (face image, document image) before submission.

If the system detects quality issues (e.g., blurry image, poor lighting), the user may be prompted to retake the photo.

However, users do not see how the model interprets their inputs internally.


2. Review by Candidate Group (Human Review Process)

In some cases, if the model flags an application as suspicious or inconclusive, a manual review team (candidate group) may inspect the input images and outputs.

This happens in high-risk scenarios, such as suspected fraud or identity mismatches.

The human reviewers may override or confirm the model's decision based on additional checks.


3. User Access to Candidate Output (Final Decision)

Users typically see only the final outcome (e.g., "Identity Verified" or "Verification Failed").

The detailed model outputs (scores, extracted features, or intermediate decisions) are usually not shared with users.

Some systems may provide error reasons (e.g., “Face does not match ID” or “Document unreadable”), but not raw model scores.



---

Summary for MRM Documentation

User Review of Inputs: Users can verify and resubmit images if quality checks fail, but they do not review how the model interprets inputs.

Candidate Group Review: If the model flags suspicious cases, human reviewers may inspect inputs and override the decision.

User Access to Output: Users see only the final verification result, not detailed model scores or intermediate outputs.


This ensures clarity on how inputs are handled and whether they are reviewed by humans. Let me know if you need any refinements!



Mathematical Operations and Processes Used for Data Transformation

Since the exact techniques used are not fully disclosed, we can generalize the key mathematical operations and processes typically involved in a Deep Neural Network (DNN) and Optical Character Recognition (OCR)-based system for Face Liveness Detection, Face Matching, and Forgery Detection.


---

1. Data Preprocessing & Feature Extraction

Before feeding the input (images and text) into the models, various preprocessing steps are applied:

Image Processing: Images of faces and documents are resized, normalized, and enhanced to improve model performance. Techniques like noise reduction, contrast enhancement, and sharpening may be applied.

Feature Extraction: Deep learning models extract key features from face images and document text. This involves detecting facial landmarks, texture patterns, and ID document attributes (e.g., holograms, watermarks, fonts).

OCR for Text Extraction: Optical Character Recognition (OCR) is used to extract text from identity documents. This process involves detecting text regions, segmenting characters, and recognizing printed or handwritten text.



---

2. Face Liveness Detection (Detecting Real vs. Fake Faces)

A deep learning-based model processes facial images or videos to determine if the face is live or a spoof attack (e.g., a photo or video replay).

The model likely analyzes color patterns, depth information, micro-movements, and reflection properties to distinguish real faces from spoofed attempts.

If video-based detection is used, the system may analyze frame sequences to check for unnatural movements or screen reflections.



---

3. Face Matching (Comparing Live Face with ID Photo)

A deep learning model compares the user’s face with the photo on the submitted identity document.

The system converts both images into feature vectors (numerical representations of facial attributes) and measures their similarity.

A similarity score is generated to determine whether the two faces belong to the same person.



---

4. Forgery Detection (Detecting Altered Identity Documents)

A deep learning model is used to identify physically or digitally altered documents by analyzing various elements such as:

Photo Manipulation: Checking if the document photo has been swapped or altered.

Text Modification: Detecting tampered text fields (e.g., changed name or date of birth).

Document Layout Analysis: Verifying if fonts, spacing, and alignment match known document templates.

Compression Artifacts & Inconsistencies: Identifying unusual artifacts that suggest digital forgery.


OCR is also used to extract and validate document details against known templates or databases.



---

5. Score Aggregation & Decision Making

The system combines the outputs of the three models (Liveness, Face Match, and Forgery Detection) into a final validation score.

A weighting mechanism determines the contribution of each model to the final decision.

If any of the models detect fraud, the final score is adjusted accordingly, and the system decides whether to accept or reject the user’s application.



---

How to Document in MRM?

Data Transformation: "The input data (face images, ID documents) undergo preprocessing and feature extraction using DNN-based models and OCR techniques."

Face Liveness Detection: "The system detects whether the input face is live or spoofed based on deep learning features such as texture, depth, and movement analysis."

Face Matching: "A feature-based comparison model generates a similarity score to determine if the live face matches the ID document photo."

Forgery Detection: "The system analyzes identity documents for physical or digital alterations using deep learning and OCR-based validation."

Final Decision: "A single validation score is generated by aggregating individual model scores, with predefined thresholds for acceptance or rejection."


This provides a high-level explanation of the mathematical processes without requiring exact details of the model implementation. Let me know if you need any refinements!


