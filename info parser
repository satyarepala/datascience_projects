When documenting assumptions for Face Liveness Detection, Face Match, and Forgery Detection Models in MRM documentation, you should outline the key transformations from input to output. Since these models work together to produce a single score for user validation, your assumptions should cover data, preprocessing, model behavior, and integration.


---

Key Assumptions for Transforming Input to Output

1. Input Data Assumptions

The captured facial image or video is of sufficient quality (adequate resolution, proper lighting, minimal occlusions).

The input image comes from a real user at the time of submission (not a previously captured or synthetic image).

No significant pose variations, extreme facial expressions, or makeup changes affect model performance.

If multiple frames are used, the frames are sequential and not altered by the user.


2. Preprocessing Assumptions

Face detection module correctly identifies and crops the face without missing key features.

Images are normalized (resized, color-adjusted, aligned) before feeding into the model.

Any transformations (e.g., grayscale conversion, histogram equalization) do not introduce bias.


3. Model-Specific Assumptions

A. Face Liveness Detection Assumptions

The model correctly differentiates between live faces and spoofing attempts (printed photos, video replays, 3D masks).

Infrared or depth-based methods (if used) are correctly capturing real vs. fake faces.

The model assumes that presentation attacks (spoofing attempts) follow patterns it has seen in training.


B. Face Match Assumptions

The model assumes the reference image (stored face) is an accurate representation of the true user.

Face embeddings are assumed to be robust across different conditions (lighting, angles, age variations).

A fixed threshold is set to determine a match, assuming a trade-off between false accept and false reject rates.


C. Forgery Detection Assumptions

The model can detect image/video manipulations (deepfakes, GAN-generated images).

It assumes forgery patterns from training data generalize to real-world attempts.

If metadata or compression artifacts are used, they reliably indicate alterations in the image/video.


4. Integration and Score Calculation Assumptions

The three models are weighted and combined appropriately to generate a single validation score.

Assumes each model's score contributes meaningfully (e.g., a user failing liveness should lower the final score significantly).

Assumes no adversarial attacks (e.g., adversarial perturbations, synthetic noise) affecting model decisions.

The threshold used for accepting or rejecting an application is set based on business/risk strategy.



---

How to Document These Assumptions in MRM?

1. Describe how input is processed → "The system assumes the captured facial image is clear, correctly framed, and represents a real person."


2. Explain model-specific logic → "The face match model assumes embeddings are invariant to minor pose changes."


3. Discuss integration assumptions → "The final score assumes each sub-model contributes to the overall decision fairly based on predefined weights."


4. Acknowledge limitations → "This model may not generalize to unseen attack types that were not present in training data."



Would you like me to refine any specific part based on your institution’s model validation framework?

