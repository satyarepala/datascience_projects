
You're absolutely right! The Forgery Detection Model is specifically designed to detect physically or digitally altered documents, so we shouldn't assume upfront that documents are always unaltered. Instead, we should phrase the assumption in a way that acknowledges potential forgeries while setting realistic expectations for model performance.

Here’s the corrected assumption list:


---

Key Assumptions for Transforming Input to Output

1. Input Data Assumptions

The captured face image or video is of sufficient quality (adequate resolution, proper lighting, minimal occlusions).

The identity document (ID) image is provided in full (not cropped or incomplete).

The model assumes that some documents may be altered (digitally manipulated or physically forged), and the system is designed to detect such modifications.

The model assumes users may attempt fraud, and it is trained to identify tampered IDs, swapped photos, or manipulated text.


2. Preprocessing Assumptions

The system correctly detects and extracts the face region from both the selfie and the ID image.

OCR (Optical Character Recognition) accurately extracts text details from the ID (name, DOB, ID number), though some errors may occur due to poor quality images.

The system assumes document templates are recognizable and can classify IDs by country or issuing authority for better validation.

If anti-forgery features (holograms, watermarks) are analyzed, the system assumes they can be correctly detected given a high-quality image.


3. Model-Specific Assumptions

A. Face Liveness Detection Assumptions

The model assumes that most fraud attempts involve common spoofing methods (printed photos, video replays, 3D masks) and is trained to detect them.

If additional sensors (e.g., infrared, depth cameras) are used, they reliably distinguish live faces from spoof attempts.

The system assumes attackers may try to bypass liveness detection, but it can recognize known attack patterns.


B. Face Match Assumptions

The model assumes that the face detected in the ID is representative of the user, considering reasonable age variations.

Face embeddings are assumed to be robust across lighting conditions and minor pose changes.

A predefined threshold determines a match, assuming a balance between false accept and false reject rates.


C. Forgery Detection Assumptions (Including ID Verification)

The model assumes that forged identity documents will exhibit detectable inconsistencies, such as:

Photo replacement (swapped images).

Text modification (digitally altered names, DOB, or ID numbers).

Tampered security features (missing holograms, fake barcodes).


The model assumes training data covers common forgery patterns but may not generalize perfectly to novel fraud techniques.

The model assumes that some genuine documents may have minor damage or wear, which should not be falsely classified as fraud.


4. Integration and Score Calculation Assumptions

The three models (Liveness, Face Match, Forgery Detection) contribute to a single validation score based on predefined weighting.

If any sub-model detects potential fraud, the final score is adjusted accordingly.

The threshold for acceptance is set based on risk appetite, balancing fraud prevention with user experience.

The system assumes that false positives and false negatives are minimized through regular model updates and retraining.



---

How to Document These Assumptions in MRM?

1. Describe input conditions → "Users may submit genuine or altered identity documents, and the system detects forgery patterns."


2. Explain document verification logic → "Forgery detection assumes altered documents leave detectable traces, such as inconsistencies in face-photo alignment or tampered text fields."


3. Discuss fraud detection scope → "The system assumes it can detect common fraud techniques but may require retraining for new attack types."


4. Acknowledge limitations → "Highly sophisticated forgeries (e.g., advanced deepfake IDs) may not always be detected without additional forensic checks."




---

This version now correctly reflects that documents can be forged and that the model is designed to detect these alterations, rather than assuming all documents are legitimate. Let me know if you need any further refinements!

