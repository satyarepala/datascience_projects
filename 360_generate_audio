from transformers import pipeline
from datasets import load_dataset
import soundfile as sf
from pydub import AudioSegment
import io
import numpy as np

# Initialize the text-to-speech pipeline
synthesiser = pipeline("text-to-speech", "microsoft/speecht5_tts")

# Load speaker embeddings
embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
speaker_embedding = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)
# You can replace this embedding with your own as well.

# Generate speech
speech = synthesiser("Hello, my dog is cooler than you!", forward_params={"speaker_embeddings": speaker_embedding})

# Save the speech to a WAV file
wav_buffer = io.BytesIO()
sf.write(wav_buffer, speech["audio"], samplerate=speech["sampling_rate"], format='wav')
wav_buffer.seek(0)

# Convert the WAV file to MP3
audio = AudioSegment.from_file(wav_buffer, format="wav")
audio.export("speech.mp3", format="mp3")

print("Audio generated and saved as speech.mp3")
